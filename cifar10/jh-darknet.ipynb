{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "PATH = \"data/cifar10/\"\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_stats(stats, sz, pad=sz//8, \n",
    "        aug_tfms=[RandomFlip()])#, RandomLighting(0.1,0.1), RandomRotate(2)])\n",
    "    return ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(32,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2)\n",
    "        self.bn = nn.BatchNorm2d(nf, momentum=0.01)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        \n",
    "    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, ni):\n",
    "        super().__init__()\n",
    "        self.conv1=ConvLayer(ni, ni//2, ks=1)\n",
    "        self.conv2=ConvLayer(ni//2, ni, ks=3)\n",
    "        \n",
    "    def forward(self, x): return self.conv2(self.conv1(x)) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def make_group_layer(self, ch_in, num_blocks, stride=1):\n",
    "        return [ConvLayer(ch_in,ch_in*2,stride=stride)\n",
    "               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes, start_nf=32):\n",
    "        super().__init__()\n",
    "        nf = start_nf\n",
    "        layers = [ConvLayer(3, nf, ks=3, stride=1)]\n",
    "        for i,nb in enumerate(num_blocks):\n",
    "            layers += self.make_group_layer(nf, nb, stride=2-(i==1) )\n",
    "            nf *= 2\n",
    "        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Darknet([2, 2, 2, 2], num_classes=10, start_nf=64)\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "wd=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d2bedfeb4d4e76856cc23d7922ce83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 27/196 [00:08<00:53,  3.17it/s, loss=2.17] \n",
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.607285   1.782385   0.3763    \n",
      "    1      1.272363   1.636895   0.4246                     \n",
      "    2      1.033237   1.758246   0.4948                     \n",
      "    3      0.896742   1.085012   0.6058                      \n",
      "    4      0.776542   1.025511   0.6519                      \n",
      "    5      0.705557   0.857516   0.6926                      \n",
      "    6      0.641807   0.85887    0.7079                      \n",
      "    7      0.593627   1.147322   0.6337                      \n",
      "    8      0.552531   0.788334   0.7201                      \n",
      "    9      0.529694   1.137728   0.6404                      \n",
      "    10     0.537546   1.072297   0.6236                      \n",
      "    11     0.508255   0.760872   0.7538                      \n",
      "    12     0.492089   1.344845   0.638                       \n",
      "    13     0.468839   0.802699   0.7318                      \n",
      "    14     0.467246   0.838831   0.7384                      \n",
      "    15     0.462584   0.741202   0.7449                      \n",
      "    16     0.445151   1.017544   0.7044                      \n",
      "    17     0.452308   0.967458   0.6883                      \n",
      "    18     0.442972   0.687035   0.7674                      \n",
      "    19     0.423147   1.485148   0.6135                      \n",
      "    20     0.438405   0.668173   0.7763                      \n",
      "    21     0.424903   0.826327   0.7594                      \n",
      "    22     0.432861   1.162611   0.6666                      \n",
      "    23     0.415272   0.89901    0.7226                      \n",
      "    24     0.403668   1.021803   0.6777                      \n",
      "    25     0.400473   1.51961    0.633                       \n",
      "    26     0.397088   0.840669   0.7278                      \n",
      "    27     0.386005   1.445935   0.6231                      \n",
      "    28     0.381891   0.579876   0.8035                      \n",
      "    29     0.363279   1.279317   0.6457                      \n",
      "    30     0.359263   0.811017   0.7343                      \n",
      "    31     0.352395   0.947545   0.7337                      \n",
      "    32     0.364287   0.980569   0.7086                      \n",
      "    33     0.339795   0.800827   0.7496                      \n",
      "    34     0.347028   0.670413   0.7883                      \n",
      "    35     0.310584   0.9301     0.7223                      \n",
      "    36     0.316263   0.556238   0.8171                      \n",
      "    37     0.311938   0.886894   0.7363                      \n",
      "    38     0.304732   0.50695    0.8289                      \n",
      "    39     0.290187   0.70144    0.7809                      \n",
      "    40     0.277548   0.512075   0.8256                      \n",
      "    41     0.26283    0.664847   0.7948                      \n",
      "    42     0.242247   0.578406   0.8178                      \n",
      "    43     0.22146    0.595003   0.8156                      \n",
      "    44     0.200987   0.391919   0.8728                      \n",
      "    45     0.169258   0.36357    0.8752                      \n",
      "    46     0.13136    0.269723   0.9071                      \n",
      "    47     0.094107   0.239493   0.9198                       \n",
      "    48     0.065369   0.227403   0.9311                       \n",
      "    49     0.057383   0.231337   0.928                        \n",
      "    50     0.051239   0.219542   0.935                        \n",
      "    51     0.043529   0.216334   0.9347                       \n",
      "    52     0.035755   0.212797   0.9373                       \n",
      "    53     0.030198   0.226975   0.9348                       \n",
      "    54     0.026502   0.227109   0.9379                       \n",
      "    55     0.024314   0.227171   0.938                        \n",
      "    56     0.023086   0.22152    0.9407                       \n",
      "    57     0.016723   0.221557   0.9399                       \n",
      "    58     0.015083   0.216067   0.9399                       \n",
      "    59     0.013061   0.218016   0.9405                       \n",
      "\n",
      "CPU times: user 1h 3min 44s, sys: 19min 12s, total: 1h 22min 56s\n",
      "Wall time: 56min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.21802]), 0.9405]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# darknet 2222 lr 1.3 bn_mom 0.01\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=60, use_clr_beta=(30, 20, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4da4e01ebd4a999fbce8c10cd02d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.533084   1.725181   0.4627    \n",
      "    1      1.224625   1.241789   0.5727                     \n",
      "    2      0.995259   1.005162   0.6476                      \n",
      "    3      0.865179   0.949657   0.6642                      \n",
      "    4      0.756122   0.854677   0.6968                      \n",
      "    5      0.692097   1.110497   0.6578                      \n",
      "    6      0.635014   0.805524   0.7227                      \n",
      "    7      0.588518   0.759759   0.7334                      \n",
      "    8      0.567764   0.868924   0.7131                      \n",
      "    9      0.547826   0.700656   0.7645                      \n",
      "    10     0.524676   1.005113   0.6889                      \n",
      "    11     0.50653    0.721323   0.7645                      \n",
      "    12     0.493718   1.125408   0.6608                      \n",
      "    13     0.479434   0.756994   0.7639                      \n",
      "    14     0.475674   0.73913    0.7589                      \n",
      "    15     0.464452   0.612312   0.7955                      \n",
      "    16     0.453685   0.772014   0.757                       \n",
      "    17     0.436029   0.60522    0.7943                      \n",
      "    18     0.437321   0.555058   0.8158                      \n",
      "    19     0.439846   0.819791   0.7449                      \n",
      "    20     0.420495   0.994983   0.719                       \n",
      "    21     0.416594   0.687188   0.7813                      \n",
      "    22     0.413399   0.714974   0.7787                      \n",
      "    23     0.421343   0.696471   0.7761                      \n",
      "    24     0.41174    0.853185   0.7445                      \n",
      "    25     0.411808   0.693145   0.7781                      \n",
      "    26     0.412166   0.847656   0.7456                      \n",
      "    27     0.402742   0.73174    0.772                       \n",
      "    28     0.391636   0.685092   0.7868                      \n",
      "    29     0.384671   0.635394   0.7931                      \n",
      "    30     0.364357   0.856764   0.7271                      \n",
      "    31     0.374435   0.490243   0.8325                      \n",
      "    32     0.364152   0.685217   0.7872                      \n",
      "    33     0.361441   0.724616   0.7843                      \n",
      "    34     0.344948   0.541638   0.8189                      \n",
      "    35     0.341661   0.604952   0.8152                      \n",
      "    36     0.337969   0.571531   0.8172                      \n",
      "    37     0.328699   0.55272    0.8177                      \n",
      "    38     0.32664    0.429266   0.8554                      \n",
      "    39     0.316233   0.424243   0.8555                      \n",
      "    40     0.302454   0.455984   0.8502                      \n",
      "    41     0.296169   0.61181    0.8123                      \n",
      "    42     0.283048   0.572225   0.8267                      \n",
      "    43     0.275228   0.453885   0.853                       \n",
      "    44     0.273048   0.408815   0.863                       \n",
      "    45     0.254404   0.397202   0.8715                      \n",
      "    46     0.219166   0.403471   0.868                       \n",
      "    47     0.215263   0.323341   0.8928                      \n",
      "    48     0.192285   0.37336    0.8824                      \n",
      "    49     0.163661   0.270863   0.9095                      \n",
      "    50     0.118515   0.269602   0.9151                      \n",
      "    51     0.089315   0.209591   0.9317                       \n",
      "    52     0.058886   0.212586   0.9339                       \n",
      "    53     0.05148    0.212392   0.9345                       \n",
      "    54     0.046729   0.232031   0.9343                       \n",
      "    55     0.038997   0.231949   0.9349                       \n",
      "    56     0.035254   0.233632   0.9349                       \n",
      "    57     0.03046    0.232361   0.937                        \n",
      "    58     0.027203   0.22916    0.94                         \n",
      "    59     0.020285   0.231641   0.9401                       \n",
      "    60     0.017448   0.23432    0.9405                       \n",
      "    61     0.016971   0.232452   0.9415                       \n",
      "    62     0.011784   0.23313    0.9416                       \n",
      "    63     0.011399   0.233199   0.9432                       \n",
      "    64     0.009589   0.233732   0.9422                        \n",
      "\n",
      "CPU times: user 1h 5min 54s, sys: 16min 4s, total: 1h 21min 59s\n",
      "Wall time: 57min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.23373]), 0.9422]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# darknet 2222 lr 1.3 65 cl\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=65, use_clr_beta=(30, 20, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
